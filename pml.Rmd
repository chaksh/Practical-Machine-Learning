---
title: "pml"
author: "Chaksh Katyal"
date: "10/23/2020"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
```

### Load data


```{r load-data}
load("movies.Rdata")
```



* * *

## Part 1: Data

The data set is comprised of 651 randomly sampled movies produced and released before 2016. 

The predictions/inferences can be said to be associative but not causal as the study is observational and not a controlled experiment. The predictions/inferences can be generalised to movies released in 2016 or before as random sampling has been used.

One possible bias is biased ratings of a movie but that can't be controlled so it can be ignored.

* * *

## Part 2: Research question

Develop a prediction model that predicts the imdb rating (which translates to popularity) of a movie released in 2016 (or before) using some relevant factors pertaining to the particular movie.

It would be informative and interesting to see what attributes make a movie more or less popular and how significant they are in predicting its rating.

* * *

## Part 3: Exploratory data analysis

We start by exploring various variables in the **movies** dataset to check possible associations with the imdb rating of a movie.

The first variables of interest are **best_pic_nom** and **best_pic_win**. However, a movie can only win an award if it has been nominated so the two variables are correlated and we will just use the **best_pic_nom** which tells if the movie was nominated for a best movie award.

```{r}
movies %>% select(imdb_rating,best_pic_nom) %>% group_by(best_pic_nom) %>%
  summarise(avg_rating=mean(imdb_rating))
```

We can see here that the average rating of the movies that fall in the two categories (been nominated and not been nominated) are different.

```{r}
ggplot(data=movies,aes(x=best_pic_nom,y=imdb_rating))+geom_boxplot()
```

The boxplots demonstrate that the ratings are differently distributed for the two sub-categories (no and yes for being nominated for a best movie award) and there seems to be a linear relationship between the categorical variable **best_pic_nom** and the **imdb_rating** of a movie. Also, in general, movies that have been nominated can be seen to have a somewhat higher rating. Owing to there being some association here, we will use this variable in our model.

We now move on to the **best_actor_win**, **best_actress_win** and **best_dir_win** which tell if an actor, actress or director of the movie has won an award at any time in their career for their acting/directing. These could prove to be variables of interest as award winning actors, actresses or directors are usually expected to make movies that end up being popular (and thus having a high imdb_rating). So we will explore these variables to check for any assoication with **imdb_rating**. However, to make analysis more effective we will combine them into a single variable **best_cast** which takes the value "yes" if atleast one of the actors, actresses or director have won an award and the value "no" otherwise.

```{r}
movies$best_cast<-ifelse(movies$best_actor_win=="yes"|movies$best_actress_win=="yes"
                         |movies$best_dir_win=="yes","yes","no")
movies %>% select(imdb_rating,best_cast) %>% group_by(best_cast) %>%
  summarise(avg_rating=mean(imdb_rating))
```

We obsereve here a difference between the average imdb ratings of movies which fall in the two categories (yes for an award or no for an award). We will now look at how these ratings are distributed over the two categories.

```{r}
ggplot(data=movies,aes(x=best_cast,y=imdb_rating))+geom_boxplot()
```

The variabilty of the "yes" responses to the **best_cast** variable is lesser than the "no" responses with the the median for it higher as well with less outliers and a possible linear relationship. As there seems some association between the **best_cast** and **imdb_rating** variables, we can use it in our model.

The third variable of interest is **title_type** which conveys: Type of movie (Documentary, Feature Film, TV Movie). Different types movies have different kinds of reception, for e.g., documentaries don't have the same viewership/audience as feature films do, and each have their own purpose so one could expect a difference in popularity (imdb_rating). So we explore its association with our response variable, **imdb_rating**.

```{r}
movies %>% select(imdb_rating,title_type) %>% group_by(title_type) %>%
  summarise(avg_rating=mean(imdb_rating)) %>% arrange(avg_rating)
```

We can see here a very evident difference in the average imdb ratings of movies which fall in the three categories. We can also look at how the ratings are distributed of the movies in each of these three categories.

```{r}
ggplot(data=movies,aes(x=title_type,y=imdb_rating))+geom_boxplot()
```

The boxplots show clear deviations in distributions from one film type to the other. The variabilty (middle 50% of ratings), medians and presence of outliers all differ with **title_type**. We thus again observe an association between the **title_type** variable and the response variable **imdb_rating**, so we will use it our model.

We search for more variables that might have some association with our response variable. The **genre** variable which tells us about the Genre of movie (Action & Adventure, Comedy, Documentary, Drama, Horror, Mystery & Suspense, Other), could be one such variable. This could be significant since in general, not every person enjoys every genre of movies, so that could lead to a difference in the distibution of ratings of movies of different genres.

```{r}
movies %>% select(imdb_rating,genre) %>% group_by(genre) %>%
  summarise(avg_rating=mean(imdb_rating)) %>% arrange(avg_rating)
```

The average ratings of movies of different genre vary minorly to majorily from each other depending on the genre. We further look at the distributions of the ratings of different movies in each genre.

```{r}
ggplot(data=movies,aes(x=genre,y=imdb_rating))+geom_boxplot()
```

As one would expect, the boxplots show clear deviations in distributions from one genre to the other. The variabilty (middle 50% of ratings), medians and presence of outliers all differ with **genre**. So there seems to be an association here as well between the **genre** factor and our response variable **imdb_rating**, so we can consider it in our model as well.

One last variable we will look at is the **runtime** variable which lists the runtime of a movie (in minutes). Although one would not expect runtime of a movie to have any association with its popularity, we still explore to be sure.

```{r}
with(movies,plot(imdb_rating~runtime))
```

The scatterplot shows random spread, there doesn't seem to be any relationship (linear or other) between the **runtime** and **imdb_rating** variables. So we should not use this variable in our model.

* * *

## Part 4: Modeling

The variables that we are going to consider for our linear model will be:
1. best_pic_nom
2. best_cast
3. title_type
4. genre

We have rejected other variables in the dataset as they are not relevant to our research question here, i.e., to predict the imdb rating of a movie. So we have considered only variables that have an association with it. Also, most variables in the dataset like **studio**, **director**, **actor1**, etc. are all descriptive variables about the movie which are not helpful in determining its popularity/rating.

We use the **backward elimination technique using adjusted R squared** to **select** our final model. We use this here since we want the highest prediction accuracy of the imdb rating of a movie. We will begin with the full model that involves all our variables and then remove one variable at a time to see if we can improve the adjusted R squared. We first create our full model.

```{r}
m<-lm(imdb_rating~best_pic_nom+best_cast+title_type+genre,movies)
summary(m)
```

We obsereve the Adjusted R-squared here to be 0.264. We will now remove one variable a time from the model to check if we can improve the Adjusted R-squared.

```{r}
m1<-lm(imdb_rating~best_cast+title_type+genre,movies)
summary(m1)$adj.r.squared
m2<-lm(imdb_rating~best_pic_nom+title_type+genre,movies)
summary(m2)$adj.r.squared
m3<-lm(imdb_rating~best_pic_nom+best_cast+genre,movies)
summary(m3)$adj.r.squared
m4<-lm(imdb_rating~best_pic_nom+best_cast+title_type,movies)
summary(m4)$adj.r.squared
```

We observe that the Adjusted R-squared does not go up in any of the removals so we will stick with our initial model, which was the full model with an Adjusted R-squared of 0.264.

Before we accept the model however, we need to perform **model diagnostics** to verify our model assumptions:

**Nearly normal residuals**

```{r}
qqnorm(m$residuals)
qqline(m$residuals)
```

Above is a normal probability plot of the residuals. While the plot exhibits some minor irregularities, there are no outliers that might be cause for concern and the plot fits the line almost. We can also look at the histogram. 

```{r}
ggplot(data=m,aes(x=.resid))+geom_histogram(binwidth=0.5)+xlab("Residuals")
```

The residuals histogram distribution is centred at 0, with a slight left skew which can be ignored owing to the large sample size. So the conditions for normality are satisfied looking at the normal probabilty plot and the histogram and we can safely assume nearly normal residuals.

**Constant variability of the residuals**

We look at a plot of the absolute value of the residuals against their corresponding fitted values to check for constant variance.

```{r}
ggplot(data=m,aes(x=.fitted,y=abs(.resid)))+geom_point()+geom_hline(yintercept=0,
                  linetype="dashed")+xlab("Fitted Values")+ylab("Residuals")
```

There seems to be almost constant variance with some deviation at the higher end of the graph (higher fitted values). So we must be cautious while making predictions using this, however, the deviation is not so major so as to completely reject the model. We can still proceed with using this model to make somewhat reasonable predictions.

**Independece of residuals**

To check for independence and identifying any connection between cases that are close to one another, we can look at a plot of the residuals in the order of their occurences.

```{r}
plot(m$residuals,ylab="Residuals")
```

The residuals are randomly scattered and we do not see any structure here that could be suggestive of a connection, so the residuals are independent.

**Linear relation between each variable and outcome**

We consider a plot of the residuals against the *best_pic_nom* variable, residuals against the *best_cast* variable, residuals against the *title_type* variable and residuals against the *genre* variable.

```{r}
plot(movies$best_pic_nom,m$residuals,xlab="best pic nom",ylab="residuals")
plot(as.factor(movies$best_cast),m$residuals,xlab="best cast",ylab="residuals")
plot(movies$title_type,m$residuals,xlab="title_type",ylab="residuals")
plot(movies$genre,m$residuals,xlab="genre",ylab="residuals")
```

For the *best_pic_nom* variable, we see slightly less variability for the yes group than for the no group. For the *best_cast* variable, the variability is almost constant. The variability in the groups of the *title_type* variable is major. Lastly, for the *genre* variable, the variabilty is somewhat constant across most groups barring some groups. So we have observed that the linear condition is not majorly satisfied for atleast one variable (*title_type*) here and some other model rather than a linear model might be a better fit. We will however report our predictions while taking note of these shortcomings.

We have checked the conditions for the model diagnostics and we once again look at our final selected model.

```{r}
m<-lm(imdb_rating~best_pic_nom+best_cast+title_type+genre,movies)
summary(m)
```

We will interpret the summary of our model to get a better understanding of it. The estimate column gives the slope associated with each variable, for e.g., the estimate for **best_pic_nomyes** is given as 1.13, we interpret it as, all else held constant, a movie that has been nominated for an award will have an imdb_rating higher by 1.13 on average over a movie that has not been nominated for an award. The estimates of all other variables can be similarly understood. We will interpret another variable's estimate. The estimate for **title_typeFeature Film** is given to be -0.87, it translates as all else held constant, a movie that is a Feature Film will have an imdb_rating lower by 0.87 on average than a movie that is a Documentary.

The standard error column holds the standard deviation corresponding to each estimate in the same row as itself. The t-value lists the t factor for the t-hypothesis test, where H0: Beta_1 = 0 and HA: Beta_1!=0. Here Beta_1 corresponds to the slope/estimate of an explanatory variable. The last column Pr(>|t|) holds the p-value for the previously stated hypothesis test. The p-value gives us an idea as to which explanatory variables are significant in deteremining our response variable.

The F-statistic at the bottom comes from the hypothesis test that determines if the model in its entirety is significant or useful in determining the repsonse variable. The p-value next to the F-statistic is the p-value for the same hypothesis test. For our model, the p-value is < 2.2e-16 which is a very small value and tells us that our model is a significant predictor of the **imdb_rating** of a movie.

The multiple R-squared value explains the variability in the response variable that is explained by the model. Here, 27.99% of the variabilty in the **imdb_rating** of a movie is explained by our model. The adjusted R-squared is the R-squared value with a penalty applied for the number of predictors in the model (4 for our model). The adjusted R-squared for our model is 26.4%.

The equation to predict the **imdb_rating** based on this model would be:

imdb_rating_hat = 6.82 + 1.13xbest_pic_nomyes + 0.14xbest_castyes - 0.87xtitle_typeFeature Film - 1.41xtitle_typeTV Movie - 0.07xgenreAnimation + 0.65xgenreArt House & International - 0.26xgenreComedy + 0.86xgenreDocumentary + 0.62xgenreDrama - 0.19xgenreHorror + 1.03xgenreMusical & Performing Arts + 0.43xgenreMystery & Suspense + 0.53xgenreOther - 0.207xgenreScience Fiction & Fantasy

* * *

## Part 5: Prediction

We will predict the imdb rating of the movie **La La Land** that was released in 2016. We first check if isn't already present in the dataset.

```{r}
sum(grepl("la la land",movies$title,ignore.case = TRUE))
```

Since the movies is not present in the dataset, we will proceed with the prediction. The specifics pertaining to the movie are: has been nominated for an award, actor/ actress/ director have received an award, Film Type: Feature Film and Genre: Drama. Also checking the imdb official website, the actual rating of the movie is 8.0/10. We now apply our model to predict the imdb rating:

```{r}
lalaland<-data.frame(best_pic_nom="yes",best_cast="yes",title_type="Feature Film",
                     genre="Drama")
predict(m,lalaland)
```

We get a predicted imdb rating of 7.85 which is not too off from the actual rating and quite close to it. So our model works sufficiently well in this case. We can also deal with the uncertainity around this value:

```{r}
predict(m,lalaland,interval="prediction",level=0.95)
```

Interpreting this result, we are 95% confident that the imdb_rating of the movie **La La Land** is between 5.98 and 9.72, which it actually is (8.0/10 from the website). The model predicts the rating successfully.

**References:**


[La La Land Oscar Nominations Film/Cast](https://www.google.com/search?q=la+la+land+oscar&oq=la+la+land+o&aqs=chrome.2.69i57j0l6j69i60.15069j1j7&sourceid=chrome&ie=UTF-8)

[La La Land Imdb Page (Genre/Film Type/Rating)](https://www.imdb.com/title/tt3783958/)

* * *

## Part 6: Conclusion

We have come to end of our research. We started with exploring variables to check for association with our response variable *imdb_rating* and chose four variables to go ahead with our model. The model does have shortcomings, specifically in the linearity relationship between a few variables and the residuals and the slight deviation from the constant variation of the residuals. These differences guide us in the direction of a linear model not being the perfect fit here and maybe going for some other model that suits the data better.

However, the model that we have developed is not completely redundant and provides sufficiently significant predictions as was evident from the example of the movie we predcited the ratings for. We thus conclude with a promising model that inspires one to study modeling further to be more efficient in one's findings.
